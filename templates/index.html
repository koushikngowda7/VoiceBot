<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Zoro VoiceBot</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #1a1a1a;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            color: #fff;
        }

        .container {
            background-color: rgba(255, 255, 255, 0.1);
            padding: 30px;
            border-radius: 15px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);
            width: 100%;
            max-width: 600px;
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.1);
        }

        .zoro-container {
            text-align: center;
            margin-bottom: 20px;
            position: relative;
            width: 250px;
            height: 250px;
            margin: 0 auto 20px;
            overflow: visible;
        }

        .zoro-image {
            width: 250px;
            height: 250px;
            border-radius: 15px;
            object-fit: cover;
            object-position: top center;
            border: 3px solid #4CAF50;
            margin-bottom: 20px;
            box-shadow: 0 0 20px rgba(76, 175, 80, 0.3);
            transition: transform 0.3s ease;
        }

        .zoro-image:hover {
            transform: scale(1.05);
        }

        h1 {
            text-align: center;
            color: #4CAF50;
            margin-bottom: 30px;
            font-size: 2.5em;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);
        }

        .controls {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-bottom: 30px;
        }

        button {
            padding: 15px 30px;
            border: none;
            border-radius: 25px;
            background-color: #4CAF50;
            color: white;
            cursor: pointer;
            font-size: 16px;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 10px;
            text-transform: uppercase;
            font-weight: bold;
            letter-spacing: 1px;
        }

        button:hover {
            background-color: #45a049;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(76, 175, 80, 0.3);
        }

        button:disabled {
            background-color: #555;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }

        .status {
            text-align: center;
            margin-bottom: 20px;
            color: #4CAF50;
            font-weight: bold;
        }

        #volumeMeter {
            width: 100%;
            height: 20px;
            background-color: rgba(255, 255, 255, 0.1);
            border-radius: 10px;
            overflow: hidden;
            margin-bottom: 20px;
            border: 1px solid rgba(76, 175, 80, 0.3);
        }

        #volumeBar {
            width: 0%;
            height: 100%;
            background: linear-gradient(90deg, #4CAF50, #45a049);
            transition: width 0.1s;
        }

        .transcription {
            margin-top: 20px;
            padding: 20px;
            background-color: rgba(255, 255, 255, 0.05);
            border-radius: 10px;
            min-height: 100px;
            border: 1px solid rgba(76, 175, 80, 0.3);
        }

        .transcription p {
            margin: 0;
            color: #fff;
            font-size: 1.1em;
            line-height: 1.5;
        }

        .icon {
            width: 20px;
            height: 20px;
        }

        .sword-decoration {
            position: absolute;
            width: 100px;
            height: 3px;
            background: linear-gradient(90deg, transparent, #4CAF50, transparent);
            transform: rotate(45deg);
            pointer-events: none;
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }

        .recording .zoro-image {
            animation: pulse 2s infinite;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="zoro-container">
            <img src="{{ url_for('static', path='images/zorro.png') }}" alt="Roronoa Zoro" class="zoro-image">
        </div>
        <h1>Zoro VoiceBot</h1>
        
        <div id="volumeMeter">
            <div id="volumeBar"></div>
        </div>

        <div class="controls">
            <button id="recordButton">
                <svg class="icon" viewBox="0 0 24 24">
                    <circle cx="12" cy="12" r="6" fill="currentColor"/>
                </svg>
                Start Recording
            </button>
            <button id="stopButton" disabled>
                <svg class="icon" viewBox="0 0 24 24">
                    <rect x="8" y="8" width="8" height="8" fill="currentColor"/>
                </svg>
                Stop
            </button>
        </div>

        <div class="status" id="status">Ready to record</div>

        <div class="transcription">
            <p id="transcription"></p>
        </div>

        <div class="sword-decoration" style="top: 20%; left: -50px;"></div>
        <div class="sword-decoration" style="bottom: 20%; right: -50px;"></div>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let ws;
        let volumeInterval;

        const recordButton = document.getElementById('recordButton');
        const stopButton = document.getElementById('stopButton');
        const status = document.getElementById('status');
        const transcription = document.getElementById('transcription');
        const volumeBar = document.getElementById('volumeBar');

        // WebSocket setup
        function setupWebSocket() {
            ws = new WebSocket(`ws://${window.location.host}/ws`);
            
            ws.onmessage = async function(event) {
                const response = JSON.parse(event.data);
                
                if (response.type === 'transcription') {
                    transcription.textContent = response.text;
                    
                    // Play the response audio
                    const audio = new Audio(`data:audio/mp3;base64,${response.audio}`);
                    await audio.play();
                } else if (response.type === 'error') {
                    status.textContent = `Error: ${response.message}`;
                }
            };

            ws.onerror = function(error) {
                console.error('WebSocket error:', error);
                status.textContent = 'WebSocket error occurred';
            };
        }

        // Audio recording setup
        async function setupAudioRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        channelCount: 1,
                        sampleRate: 16000,
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                });
                
                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm',
                    audioBitsPerSecond: 16000
                });

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };

                mediaRecorder.onstop = async () => {
                    try {
                        const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                        const audioContext = new AudioContext({
                            sampleRate: 16000
                        });
                        
                        // Convert blob to array buffer
                        const arrayBuffer = await audioBlob.arrayBuffer();
                        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                        
                        // Get audio data as Float32Array
                        const inputData = audioBuffer.getChannelData(0);
                        
                        // Convert to 16-bit PCM
                        const outputData = new Int16Array(inputData.length);
                        for (let i = 0; i < inputData.length; i++) {
                            const s = Math.max(-1, Math.min(1, inputData[i]));
                            outputData[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                        }
                        
                        // Create WAV header
                        const buffer = new ArrayBuffer(44 + outputData.length * 2);
                        const view = new DataView(buffer);
                        
                        // Write WAV header
                        const writeString = (view, offset, string) => {
                            for (let i = 0; i < string.length; i++) {
                                view.setUint8(offset + i, string.charCodeAt(i));
                            }
                        };
                        
                        writeString(view, 0, 'RIFF');
                        view.setUint32(4, 36 + outputData.length * 2, true);
                        writeString(view, 8, 'WAVE');
                        writeString(view, 12, 'fmt ');
                        view.setUint32(16, 16, true);
                        view.setUint16(20, 1, true);
                        view.setUint16(22, 1, true);
                        view.setUint32(24, 16000, true);
                        view.setUint32(28, 16000 * 2, true);
                        view.setUint16(32, 2, true);
                        view.setUint16(34, 16, true);
                        writeString(view, 36, 'data');
                        view.setUint32(40, outputData.length * 2, true);
                        
                        // Write audio data
                        const output = new Int16Array(buffer, 44);
                        output.set(outputData);
                        
                        // Convert to base64
                        const wavBlob = new Blob([buffer], { type: 'audio/wav' });
                        const reader = new FileReader();
                        
                        reader.onload = () => {
                            const base64Data = reader.result.split(',')[1];
                            ws.send(base64Data);
                            ws.send('DONE');
                        };
                        
                        reader.readAsDataURL(wavBlob);
                        
                    } catch (error) {
                        console.error('Error processing audio:', error);
                        status.textContent = 'Error processing audio';
                    }
                    
                    // Clear audio chunks
                    audioChunks = [];
                };

                // Setup volume meter
                const audioContext = new AudioContext();
                const analyser = audioContext.createAnalyser();
                const microphone = audioContext.createMediaStreamSource(stream);
                microphone.connect(analyser);
                analyser.fftSize = 256;
                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);

                function updateVolume() {
                    analyser.getByteFrequencyData(dataArray);
                    const average = dataArray.reduce((a, b) => a + b) / bufferLength;
                    const volume = (average / 255) * 100;
                    volumeBar.style.width = `${volume}%`;
                }

                volumeInterval = setInterval(updateVolume, 100);

            } catch (error) {
                console.error('Error accessing microphone:', error);
                status.textContent = 'Error accessing microphone';
            }
        }

        // Button event listeners
        recordButton.onclick = async () => {
            audioChunks = [];
            setupWebSocket();
            await setupAudioRecording();
            
            mediaRecorder.start(100);
            recordButton.disabled = true;
            stopButton.disabled = false;
            status.textContent = 'Recording...';
            document.querySelector('.zoro-container').classList.add('recording');
        };

        stopButton.onclick = () => {
            mediaRecorder.stop();
            recordButton.disabled = false;
            stopButton.disabled = true;
            status.textContent = 'Processing...';
            clearInterval(volumeInterval);
            volumeBar.style.width = '0%';
            document.querySelector('.zoro-container').classList.remove('recording');
        };
    </script>
</body>
</html> 